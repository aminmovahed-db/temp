h1. DLT Direct Publishing Mode – Backing Table Location Changes (Resolved Identifiers)

h2. Overview
Delta Live Tables (DLT) *Direct Publishing Mode (DPM)* changes how Materialized Views (MVs) and Streaming Tables (STs) store their artifacts.  
Instead of using a single global pipeline storage path, DLT now stores *backing Delta tables, event logs, checkpoints, and internal metadata* based on the table’s *resolved identifier* (`catalog.schema.table`).

This provides cleaner governance, stronger isolation, and simpler multi-domain operation.

----

h2. 1. Resolved Identifiers Determine Storage Location
Artifacts for each MV/ST are created directly inside the *catalog and schema* of the published table.

Examples:
* `finance.gold.sales_summary`
* `operations.staging.invoices_stream`

This ensures all associated artifacts live alongside the logical table definition.

----

h2. 2. Namespace Determined by Pipeline Config and Code
A pipeline may define default catalog/schema values, but *fully qualified names always take precedence*.

{code:sql}
CREATE MATERIALIZED VIEW finance.gold.txn_summary AS SELECT ...;
{code}

{code:python}
@dlt.table(name="bronze.transactions")
def transactions():
    ...
{code}

The resolved identifier controls where artifacts are stored, regardless of pipeline defaults.

----

h2. 3. Built-in Domain and Stage Separation
Using separate catalogs/schemas naturally isolates both business domains and processing layers.

h3. Domain separation
* `finance.*`
* `marketing.*`

h3. Stage separation
* `bronze.*`
* `silver.*`
* `gold.*`

All artifacts, logs, and metadata remain fully isolated.

----

h2. 4. Benefits of the New Model
* *Stronger governance:* Artifacts inherit Unity Catalog permissions.
* *Cost & ownership clarity:* Storage aligns with domains.
* *Multi-team scalability:* Teams avoid interfering with each other's projects.
* *Cleaner operations:* Everything tied to a table lives in its own namespace.

----

h2. 5. Accessing Backing Tables (Required Permissions)
Backing tables in DPM are *hidden internal objects* stored in the same catalog/schema as the published MV/ST.  
They do *not* appear in standard table listings.

To query or inspect a backing table, **all** conditions below must be met:

h3. 1. Knowledge of the backing table name
This may be:
* A resolved identifier  
* An obfuscated UUID-like internal name  

h3. 2. Correct Unity Catalog permissions
Users must have:
* Permissions on the *catalog*  
* Permissions on the *schema*  
* Permissions (e.g., SELECT) on the *backing table itself*  

Pipeline owners typically have this; others require explicit grants.

h3. 3. Querying must occur outside the pipeline context
Access to backing tables is only possible using:
* Spark SQL  
* Databricks SQL  

They do not appear in the DLT UI or in `SHOW TABLES`.

h3. 4. Backing tables behave like normal Delta tables
They inherit:
* Storage configuration
* Encryption settings
* Catalog-level security

But remain hidden unless the user has:
* The identifier, *and*
* Appropriate permissions

----

h2. 6. Impact on Backup and Restore Processes
Since DPM stores backing tables, event logs, and system metadata *inside each table’s schema/catalog*, backup and restore procedures must include these hidden objects.

Backup/restore workflows must:
* Capture backing tables across all schemas
* Include domain-specific event logs and checkpoints
* Restore artifacts into the correct catalog/schema locations

This ensures full recoverability of DLT pipelines under Direct Publishing Mode.

----

h2. Example Patterns

h3. SQL
{code:sql}
CREATE MATERIALIZED VIEW finance.gold.txn_summary AS SELECT ...;
CREATE STREAMING TABLE operations.staging.device_events AS SELECT ...;
{code}

h3. Python DLT
{code:python}
@dlt.table(name="bronze.transactions")
def transactions():
    return ...
{code}

Artifacts are stored under:
* `finance.gold`
* `operations.staging`
* `bronze`
